import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset

# Simple dataset: X = audio features, y = meaning labels
class CatVoiceDataset(Dataset):
    def __init__(self, features, labels):
        self.X = torch.tensor(features, dtype=torch.float32)
        self.y = torch.tensor(labels, dtype=torch.long)
    def __len__(self):
        return len(self.X)
    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

# Simple feedforward classifier
class CatVoiceClassifier(nn.Module):
    def __init__(self, input_dim, num_classes):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, num_classes)
        )
    def forward(self, x):
        return self.net(x)

# Dummy data loading (replace with your actual feature extraction)
# features = ... # shape: (num_samples, num_features)
# labels = ...   # shape: (num_samples,), integer class labels
# For demo:
# features, labels = load_features_and_labels()

# Hyperparameters
input_dim = 20  # Number of audio features (e.g., MFCCs)
num_classes = 3 # e.g., hungry, angry, happy
batch_size = 16
epochs = 10

# dataset = CatVoiceDataset(features, labels)
# loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
# model = CatVoiceClassifier(input_dim, num_classes)
# optimizer = optim.Adam(model.parameters(), lr=0.001)
# criterion = nn.CrossEntropyLoss()

# Training loop
# for epoch in range(epochs):
#     for X_batch, y_batch in loader:
#         optimizer.zero_grad()
#         outputs = model(X_batch)
#         loss = criterion(outputs, y_batch)
#         loss.backward()
#         optimizer.step()
#     print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}")

# torch.save(model.state_dict(), 'cat_voice_model.pt')